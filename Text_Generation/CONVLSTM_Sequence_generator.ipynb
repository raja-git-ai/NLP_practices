{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sequence_generator.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1grBcP2PU-MT28RVlMj0OmQ3h2XAVKho7","authorship_tag":"ABX9TyPzbFYcg5gVayRg547kKtGR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"n3WLalBdS7Xh","colab_type":"text"},"source":["**Text Generation with LSTM** "]},{"cell_type":"code","metadata":{"id":"lgHwSoktQIlY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595825243040,"user_tz":-330,"elapsed":1829,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}}},"source":["import numpy\n","# 1. What we want ot do is use the Sequence models as generative models \n","# 2. What we have is sequence of words/charectors or a storybook in text format \n","# 3. What we want to achieve is we want to generate a sentence or para from the storybook given few random \n","#    charecotrs or words.\n","# We are going to consider the entire book as trian data.\n","# Because this is a non trevial problem with non repeateable sequences.\n","# Step:1 :- Load the text into memory\n","little_women = open(\"/Little_women.txt\").read()\n","# For now I am just taking 1/8 th of the story \n","little_women = little_women[10000:len(little_women)//8]"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCFoQ1AVr1Qe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595825250718,"user_tz":-330,"elapsed":1234,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}},"outputId":"2b2ac2d1-3aa7-4f51-ac46-47e9ae6ff544"},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","#from fastai import *\n","#master_bar, progress_bar = force_console_behavior()\n","#fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QKJNoWHOQOd-","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"NcQ6hwoqQO3E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1595825252715,"user_tz":-330,"elapsed":1403,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}},"outputId":"0e3f5f11-b8fc-40c0-bac5-21e3f02e1624"},"source":["# Step 2:- geter the number of unique charectors \n","# 2.1 Lower all the text from our storybook\n","little_women = little_women.lower()\n","# We have filterd only the alphabets from the \n","chars =[char for char in list(set(little_women)) if(char.isalpha())] \n","# Adding \".\" and \"?\" \",\" \"space\" and \"'\" in the vocabulary\n","# Also assigning a default char \"dc\"\n","default_char = \"dc\"\n","chars = chars+[\" \",\".\",\"?\",\"'\",\",\",default_char]\n","# Getting the vocab length\n","vocab_len = len(chars)\n","total_chars = len(little_women)\n","print(\"Vocab length;- \",vocab_len)\n","print(\"Total number of charectors present:- \",total_chars)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Vocab length;-  32\n","Total number of charectors present:-  119059\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_i4P2DYCZotY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595825258399,"user_tz":-330,"elapsed":1635,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}}},"source":["# Step 3:- Assigning an integer number with each char \n","char_to_int_mapping = {chars[i]:i for i in range(len(chars))}\n","# Step 4:- reversing the char to int to int to char\n","int_to_char_mapping = {integer:char for (char,integer) in char_to_int_mapping.items()}"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"qUY07_cISacP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595825262003,"user_tz":-330,"elapsed":4588,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}}},"source":["# Step 5:- We are going to consider a sequence length of 100 \n","# also we create a sequence of integers with a corrosponding sequence of charectors\n","seq_len  = 100\n","X = []\n","y = []\n","\n","for i in range(total_chars-seq_len):\n","  input_seq = little_women[i:seq_len+i]\n","  output_char = little_women[i+seq_len]\n","  X.append([char_to_int_mapping.get(char,char_to_int_mapping[default_char]) for char in input_seq])\n","  y.append(char_to_int_mapping.get(output_char,char_to_int_mapping[default_char]))\n","y = numpy.eye(vocab_len)[y]"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"thlcpkp-V-eZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595825262004,"user_tz":-330,"elapsed":3417,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}}},"source":["# Step 6:- We can cunstruct the network now \n","# Here we will use the combination of Convolution with LSTM to predict the next most likely charector\n","# and by repeating this cycle we will be able to complete the sentence/s\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D,Dense,MaxPool1D,LSTM,Embedding,Dropout,Flatten,TimeDistributed\n","from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n","from tensorflow.keras.preprocessing import sequence"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"-RjdClwgzXgt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595825262482,"user_tz":-330,"elapsed":2840,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}}},"source":["X = sequence.pad_sequences(X,seq_len)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpe-CQRmmd43","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595825262489,"user_tz":-330,"elapsed":1734,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}}},"source":["# Defining callbacks\n","callbacks_ = [ModelCheckpoint(\"seq_to_seq.h5\",monitor=\"loss\",save_best_only=True),\n","              #ReduceLROnPlateau(monitor=\"loss\",patience=5,factor=0.2,verbose=0),\n","              EarlyStopping(monitor=\"loss\",patience=5,mode=\"auto\",verbose=0)]"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCnRFnHndWU-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":348},"executionInfo":{"status":"ok","timestamp":1595828708449,"user_tz":-330,"elapsed":2261,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}},"outputId":"53a451f0-0ccd-4f15-cb31-d4a9cf33d79a"},"source":["# cunstrecting the model \n","# let's assume an embedding vector length of 100\n","embedding_vec_len = 100\n","lstm_model = Sequential()\n","lstm_model.add(Embedding(len(char_to_int_mapping)+1,embedding_vec_len,input_length=seq_len))\n","# We are using convolution because it will give us good performance and also help in extracting meaningful features\n","lstm_model.add(Conv1D(filters=32,kernel_size=4,activation='relu'))\n","# We can experiment with maxPooling , In my case it didn't work well.\n","#lstm_model.add(MaxPool1D(pool_size=2,padding=\"same\"))\n","#lstm_model.add(TimeDistributed(Flatten()))\n","lstm_model.add(LSTM(250,activation=\"tanh\",return_sequences=True))\n","#lstm_model.add(LSTM(250,activation=\"tanh\",return_sequences=True))\n","lstm_model.add(LSTM(200,activation=\"tanh\"))\n","lstm_model.add(Dense(len(char_to_int_mapping),activation=\"softmax\"))\n","lstm_model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\")\n","lstm_model.summary()"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Model: \"sequential_22\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_22 (Embedding)     (None, 100, 100)          3300      \n","_________________________________________________________________\n","conv1d_22 (Conv1D)           (None, 97, 32)            12832     \n","_________________________________________________________________\n","lstm_28 (LSTM)               (None, 97, 250)           283000    \n","_________________________________________________________________\n","lstm_29 (LSTM)               (None, 200)               360800    \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 32)                6432      \n","=================================================================\n","Total params: 666,364\n","Trainable params: 666,364\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sWJGccNZeoTu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"ok","timestamp":1595833581172,"user_tz":-330,"elapsed":460870,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}},"outputId":"e92a5e52-01f2-4851-e45a-e3c1deed5ee6"},"source":["history = lstm_model.fit(X,y,batch_size=1280,epochs=100,callbacks=callbacks_,use_multiprocessing=True,workers=6)"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","93/93 [==============================] - 46s 492ms/step - loss: 0.0727\n","Epoch 2/10\n","93/93 [==============================] - 45s 489ms/step - loss: 0.0376\n","Epoch 3/10\n","93/93 [==============================] - 45s 489ms/step - loss: 0.0246\n","Epoch 4/10\n","93/93 [==============================] - 45s 488ms/step - loss: 0.0194\n","Epoch 5/10\n","93/93 [==============================] - 45s 489ms/step - loss: 0.0168\n","Epoch 6/10\n","93/93 [==============================] - 45s 488ms/step - loss: 0.0150\n","Epoch 7/10\n","93/93 [==============================] - 45s 488ms/step - loss: 0.0137\n","Epoch 8/10\n","93/93 [==============================] - 45s 488ms/step - loss: 0.0126\n","Epoch 9/10\n","93/93 [==============================] - 45s 489ms/step - loss: 0.0116\n","Epoch 10/10\n","93/93 [==============================] - 45s 488ms/step - loss: 0.0108\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qHMu_IhlgNbN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"status":"ok","timestamp":1595833840453,"user_tz":-330,"elapsed":21052,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}},"outputId":"33b87540-5956-43d1-972d-73d381339145"},"source":["# Step 8: Testing our text generation capabilities\n","start = numpy.random.randint(0, len(X)-1)\n","pattern = list(X[start])\n","print(''.join([int_to_char_mapping[value] for value in pattern]).replace(default_char,\"\"))\n","result_sent = []\n","for i in range(500):\n","  x = numpy.reshape(pattern,(1,len(pattern),1))\n","  predict = lstm_model.predict(x,verbose=0)\n","  index = numpy.argmax(predict)\n","  result = int_to_char_mapping[index]\n","  result_sent.append(result)\n","  pattern.append(index)\n","  pattern = pattern[1:len(pattern)]\n","\n","print(\"result sent :- \", \"\".join(result_sent).replace(default_char,\"\"))"],"execution_count":83,"outputs":[{"output_type":"stream","text":["peared zara in a lovely blue andsilver dress, waiting for roderigo.  he came in gorgeous array, wit\n","result sent :-  hplumed cap, red cloak, chestnut lovelocks, a guitar, and the boots, ofcourse.  kneeling at the foot of the tower, he sang a serenade inmelting tones.  zara replied and, after a musical dialogue, consentedto fly.  then came the grand effect of the play.  roderigo produced arope ladder, with five steps to it, threw up one end, and invited zarato descend.  timidly she crept from her lattice, put her hand onroderigo's shoulder, and was about to leap gracefully down when alasalas for zara\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vZhJwwgEq5Y1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595833582800,"user_tz":-330,"elapsed":1595,"user":{"displayName":"Raja Kumar","photoUrl":"","userId":"13962968010408347999"}}},"source":["# we can see that we are able to generate descent output from out swquence generator.\n","# The model we used which is Convolution comined with LSTM is faster to train and perform than using plain LSTM.\n","# Where only LSTM layers may take 700 seconds per epoc to train , it just took 50 seconds on an average.\n","# Next up is increase the vocabulary on word level and perform sequence/sentence generation."],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"MG6Gb0xSEuae","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}
